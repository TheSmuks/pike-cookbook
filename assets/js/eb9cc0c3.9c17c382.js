"use strict";(self.webpackChunkpike_cookbook=self.webpackChunkpike_cookbook||[]).push([[149],{2209(n,e,t){t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>p,frontMatter:()=>a,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"network/web-automation","title":"Web Automation","description":"Introduction","source":"@site/docs/network/web-automation.md","sourceDirName":"network","slug":"/network/web-automation","permalink":"/pike-cookbook/docs/network/web-automation","draft":false,"unlisted":false,"editUrl":"https://github.com/TheSmuks/pike-cookbook/tree/main/docs/network/web-automation.md","tags":[],"version":"current","frontMatter":{"id":"web-automation","title":"Web Automation","sidebar_label":"Web Automation"},"sidebar":"tutorialSidebar","previous":{"title":"Sockets","permalink":"/pike-cookbook/docs/network/sockets"},"next":{"title":"Internet Services","permalink":"/pike-cookbook/docs/network/internet-services"}}');var r=t(4848),s=t(8453);const a={id:"web-automation",title:"Web Automation",sidebar_label:"Web Automation"},o="Web Automation",l={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Fetching a URL",id:"fetching-a-url",level:2},{value:"Simple HTTP GET Request",id:"simple-http-get-request",level:3},{value:"GET Request with Custom Headers",id:"get-request-with-custom-headers",level:3},{value:"Async HTTP Request",id:"async-http-request",level:3},{value:"Automating Form Submission",id:"automating-form-submission",level:2},{value:"POST Form Data",id:"post-form-data",level:3},{value:"JSON POST Request",id:"json-post-request",level:3},{value:"Extracting URLs",id:"extracting-urls",level:2},{value:"Link Extraction from HTML",id:"link-extraction-from-html",level:3},{value:"HTML Parsing with Standards.XML",id:"html-parsing-with-standardsxml",level:2},{value:"Parse Structured HTML",id:"parse-structured-html",level:3},{value:"Converting ASCII to HTML",id:"converting-ascii-to-html",level:2},{value:"HTML Escaping",id:"html-escaping",level:3},{value:"Session Management and Cookies",id:"session-management-and-cookies",level:2},{value:"Cookie Handling",id:"cookie-handling",level:3},{value:"Authentication",id:"authentication",level:2},{value:"HTTP Basic Auth",id:"http-basic-auth",level:3},{value:"Bearer Token (OAuth2/JWT)",id:"bearer-token-oauth2jwt",level:3},{value:"REST API Client",id:"rest-api-client",level:2},{value:"High-Level REST Client",id:"high-level-rest-client",level:3},{value:"Rate Limiting",id:"rate-limiting",level:2},{value:"Polite Crawler",id:"polite-crawler",level:3},{value:"Creating a Web Crawler",id:"creating-a-web-crawler",level:2},{value:"Basic Web Crawler",id:"basic-web-crawler",level:3},{value:"See Also",id:"see-also",level:2}];function d(n){const e={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"web-automation",children:"Web Automation"})}),"\n",(0,r.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,r.jsx)(e.p,{children:"Web automation in Pike 8 involves HTTP requests, HTML parsing, form submission, session management, and building web crawlers. This section covers practical recipes for automating web interactions using modern Pike features."}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"What this covers:"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["HTTP GET and POST requests with ",(0,r.jsx)(e.code,{children:"Protocols.HTTP"})]}),"\n",(0,r.jsx)(e.li,{children:"HTML parsing and link extraction"}),"\n",(0,r.jsx)(e.li,{children:"Form submission and cookie handling"}),"\n",(0,r.jsx)(e.li,{children:"JSON API integration"}),"\n",(0,r.jsx)(e.li,{children:"Web scraping and crawling"}),"\n",(0,r.jsx)(e.li,{children:"Rate limiting and politeness policies"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Why use it:"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Automate web interactions and testing"}),"\n",(0,r.jsx)(e.li,{children:"Build web scrapers and crawlers"}),"\n",(0,r.jsx)(e.li,{children:"Integrate with REST APIs"}),"\n",(0,r.jsx)(e.li,{children:"Monitor websites and services"}),"\n",(0,r.jsx)(e.li,{children:"Aggregate web data"}),"\n"]}),"\n",(0,r.jsx)(e.admonition,{type:"tip",children:(0,r.jsxs)(e.p,{children:["For server-side web applications, see ",(0,r.jsx)(e.a,{href:"/docs/network/cgi-programming",children:"CGI Programming"}),". This section focuses on client-side automation."]})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"fetching-a-url",children:"Fetching a URL"}),"\n",(0,r.jsx)(e.h3,{id:"simple-http-get-request",children:"Simple HTTP GET Request"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-pike",children:'//-----------------------------\n// Recipe: HTTP GET request with error handling\n//-----------------------------\n\n#pragma strict_types\n#require constant(Protocols.HTTP)\n\nvoid main() {\n    string url = "https://example.com";\n\n    // Simple GET request\n    Protocols.HTTP.Query q = Protocols.HTTP.get_url(url);\n\n    if (q->status == 200) {\n        write("Success: %d bytes\\n", sizeof(q->data()));\n        write("Content-Type: %s\\n", q->headers["content-type"]);\n\n        // Display first 200 chars\n        write("Preview: %s\\n", q->data()[0..199]);\n    } else {\n        werror("HTTP Error: %d %s\\n", q->status, q->status_desc);\n    }\n}\n'})}),"\n",(0,r.jsx)(e.h3,{id:"get-request-with-custom-headers",children:"GET Request with Custom Headers"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-pike",children:'//-----------------------------\n// Recipe: HTTP GET with custom headers\n//-----------------------------\n\n#pragma strict_types\n#require constant(Protocols.HTTP)\n\nvoid main() {\n    // Custom headers\n    mapping(string:string) headers = ([\n        "User-Agent": "PikeBot/1.0",\n        "Accept": "application/json",\n        "Accept-Language": "en-US,en;q=0.9"\n    ]);\n\n    Protocols.HTTP.Query q = Protocols.HTTP.get_url(\n        "https://api.example.com/data",\n        headers\n    );\n\n    if (q->status == 200) {\n        write("%s\\n", q->data());\n    }\n}\n'})}),"\n",(0,r.jsx)(e.h3,{id:"async-http-request",children:"Async HTTP Request"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-pike",children:'//-----------------------------\n// Recipe: Asynchronous HTTP GET\n//-----------------------------\n\n#pragma strict_types\n#require constant(Protocols.HTTP)\n\nvoid main() {\n    Protocols.HTTP.Query q = Protocols.HTTP.Query();\n\n    // Set callbacks for async operation\n    q->set_callbacks(\n        lambda() { werror("Connection failed\\n"); },\n        lambda(Protocols.HTTP.Query r) {\n            write("Got %d bytes\\n", sizeof(r->data()));\n        }\n    );\n\n    q->async_request("https://example.com", "GET", ([]));\n\n    // Keep program alive\n    sleep(5);\n}\n'})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"automating-form-submission",children:"Automating Form Submission"}),"\n",(0,r.jsx)(e.h3,{id:"post-form-data",children:"POST Form Data"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-pike",children:'//-----------------------------\n// Recipe: Submit form with POST data\n//-----------------------------\n\n#pragma strict_types\n#require constant(Protocols.HTTP)\n\nvoid main() {\n    // Form data\n    mapping(string:string) form_data = ([\n        "username": "alice",\n        "email": "alice@example.com",\n        "message": "Hello from Pike!"\n    ]);\n\n    // Build query string\n    array(string) params = map(indices(form_data), lambda(string key) {\n        return Protocols.HTTP.uri_encode(key) + "=" +\n               Protocols.HTTP.uri_encode(form_data[key]);\n    });\n    string query_string = params * "&";\n\n    // POST the form\n    Protocols.HTTP.Query q = Protocols.HTTP.post_url(\n        "https://example.com/submit",\n        form_data,\n        ([\n            "Content-Type": "application/x-www-form-urlencoded",\n            "User-Agent": "Pike FormBot/1.0"\n        ])\n    );\n\n    if (q->status >= 200 && q->status < 300) {\n        write("Form submitted successfully\\n");\n        write("Response: %s\\n", q->data());\n    }\n}\n'})}),"\n",(0,r.jsx)(e.h3,{id:"json-post-request",children:"JSON POST Request"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-pike",children:'//-----------------------------\n// Recipe: Submit JSON data via POST\n//-----------------------------\n\n#pragma strict_types\n#require constant(Protocols.HTTP)\n#require constant(Standards.JSON)\n\nvoid main() {\n    // JSON payload\n    mapping data = ([\n        "user": ([\n            "name": "Jane Doe",\n            "email": "jane@example.com",\n            "age": 28\n        ]),\n        "action": "create"\n    ]);\n\n    string json_body = Standards.JSON.encode(data);\n\n    mapping(string:string) headers = ([\n        "Content-Type": "application/json",\n        "Accept": "application/json"\n    ]);\n\n    Protocols.HTTP.Query q = Protocols.HTTP.do_method(\n        "POST",\n        "https://api.example.com/users",\n        ([]),  // query variables\n        headers,\n        0,     // follow redirects\n        json_body\n    );\n\n    if (q->status >= 200 && q->status < 300) {\n        mapping response = Standards.JSON.decode(q->data());\n        write("Created user: %s\\n", response->user->name);\n    }\n}\n'})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"extracting-urls",children:"Extracting URLs"}),"\n",(0,r.jsx)(e.h3,{id:"link-extraction-from-html",children:"Link Extraction from HTML"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-pike",children:'//-----------------------------\n// Recipe: Extract all links from HTML\n//-----------------------------\n\n#pragma strict_types\n\nvoid main() {\n    string url = "https://example.com";\n    Protocols.HTTP.Query q = Protocols.HTTP.get_url(url);\n\n    if (q->status != 200) {\n        werror("Failed to fetch page\\n");\n        exit(1);\n    }\n\n    string html = q->data();\n\n    // Extract all href attributes\n    object re = Regexp.PCRE.Simple("<a\\\\s+href=\\"([^\\"]+)\\"[^>]*>([^<]*)</a>");\n    array(string) links = ({});\n    int pos = 0;\n\n    while (pos < sizeof(html)) {\n        array(string) match = re->match(html, pos);\n        if (!match) break;\n\n        string link_url = match[1];\n        string link_text = match[2];\n        links += (["url": link_url, "text": link_text]);\n\n        pos = html->search(match[0], pos) + sizeof(match[0]);\n    }\n\n    // Display links\n    foreach(links; mapping link) {\n        write("[%s] %s\\n", link->text, link->url);\n    }\n\n    write("\\nFound %d links\\n", sizeof(links));\n}\n'})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"html-parsing-with-standardsxml",children:"HTML Parsing with Standards.XML"}),"\n",(0,r.jsx)(e.h3,{id:"parse-structured-html",children:"Parse Structured HTML"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-pike",children:'//-----------------------------\n// Recipe: Parse XHTML with Standards.XML\n//-----------------------------\n\n#pragma strict_types\n\nvoid main() {\n    string html = #"\n<html>\n        <head><title>Test Page</title></head>\n        <body>\n            <h1>Welcome</h1>\n            <p id=\'intro\'>This is <b>introductory</b> text.</p>\n            <ul>\n                <li>Item 1</li>\n                <li>Item 2</li>\n            </ul>\n        </body>\n    </html>";\n\n    // Parse XHTML\n    Standards.XML.Node root = Standards.XML.parse(html);\n\n    // Extract title\n    array(Standards.XML.Node) titles = root->get_elements("title");\n    if (sizeof(titles)) {\n        write("Title: %s\\n", titles[0]->get_text());\n    }\n\n    // Extract paragraph by ID\n    array(Standards.XML.Node) paras = root->get_elements("p");\n    foreach(paras; Standards.XML.Node p) {\n        mapping attrs = p->get_attributes();\n        if (attrs && attrs->id == "intro") {\n            write("Intro paragraph: %s\\n", p->get_text());\n        }\n    }\n\n    // Extract list items\n    array(Standards.XML.Node) lists = root->get_elements("ul");\n    if (sizeof(lists)) {\n        array(Standards.XML.Node) items = lists[0]->get_elements("li");\n        foreach(items; Standards.XML.Node item) {\n            write("- %s\\n", item->get_text());\n        }\n    }\n}\n'})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"converting-ascii-to-html",children:"Converting ASCII to HTML"}),"\n",(0,r.jsx)(e.h3,{id:"html-escaping",children:"HTML Escaping"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-pike",children:'//-----------------------------\n// Recipe: Escape special characters for HTML\n//-----------------------------\n\n#pragma strict_types\n\nstring html_escape(string text) {\n    text = replace(text, "&", "&amp;");\n    text = replace(text, "<", "&lt;");\n    text = replace(text, ">", "&gt;");\n    text = replace(text, "\\"", "&quot;");\n    text = replace(text, "\'", "&#39;");\n    return text;\n}\n\nvoid main() {\n    string unsafe = "<script>alert(\'XSS\')<\/script>";\n\n    write("Original: %s\\n", unsafe);\n    write("Escaped:  %s\\n", html_escape(unsafe));\n    // Output: &lt;script&gt;alert(&#39;XSS&#39;)&lt;/script&gt;\n}\n'})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"session-management-and-cookies",children:"Session Management and Cookies"}),"\n",(0,r.jsx)(e.h3,{id:"cookie-handling",children:"Cookie Handling"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-pike",children:'//-----------------------------\n// Recipe: Parse and manage cookies\n//-----------------------------\n\n#pragma strict_types\n\nmapping(string:string) parse_cookie_header(string cookie_header) {\n    mapping(string:string) cookies = ([]);\n\n    foreach(cookie_header / ";"; string cookie) {\n        string trimmed = String.trim_whites(cookie);\n        int pos = search(trimmed, "=");\n\n        if (pos > 0) {\n            string name = trimmed[0..pos-1];\n            string value = trimmed[pos+1..];\n            cookies[name] = value;\n        }\n    }\n\n    return cookies;\n}\n\nvoid main() {\n    // Simulate receiving cookies\n    string cookie_header = "session=abc123; user=john; theme=dark";\n\n    mapping(string:string) cookies = parse_cookie_header(cookie_header);\n\n    write("Cookies:\\n");\n    foreach(cookies; string name; string value) {\n        write("  %s: %s\\n", name, value);\n    }\n}\n'})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"authentication",children:"Authentication"}),"\n",(0,r.jsx)(e.h3,{id:"http-basic-auth",children:"HTTP Basic Auth"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-pike",children:'//-----------------------------\n// Recipe: Basic authentication\n//-----------------------------\n\n#pragma strict_types\n#require constant(MIME)\n\nvoid main() {\n    string credentials = "user:pass";\n    string encoded = MIME.encode_base64(credentials);\n\n    mapping(string:string) headers = ([\n        "Authorization": "Basic " + encoded\n    ]);\n\n    Protocols.HTTP.Query q = Protocols.HTTP.get_url(\n        "https://api.example.com/protected",\n        headers\n    );\n\n    if (q->status == 200) {\n        write("Authenticated successfully\\n");\n        write("%s\\n", q->data()[0..299]);\n    } else if (q->status == 401) {\n        werror("Authentication failed\\n");\n    }\n}\n'})}),"\n",(0,r.jsx)(e.h3,{id:"bearer-token-oauth2jwt",children:"Bearer Token (OAuth2/JWT)"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-pike",children:'//-----------------------------\n// Recipe: Bearer token authentication\n//-----------------------------\n\n#pragma strict_types\n#require constant(Protocols.HTTP)\n\nvoid main() {\n    string access_token = "your_token_here";\n\n    mapping(string:string) headers = ([\n        "Authorization": "Bearer " + access_token,\n        "Content-Type": "application/json"\n    ]);\n\n    Protocols.HTTP.Query q = Protocols.HTTP.get_url(\n        "https://api.example.com/resource",\n        headers\n    );\n\n    if (q->status == 200) {\n        mapping data = Standards.JSON.decode(q->data());\n        write("Resource: %O\\n", data);\n    }\n}\n'})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"rest-api-client",children:"REST API Client"}),"\n",(0,r.jsx)(e.h3,{id:"high-level-rest-client",children:"High-Level REST Client"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-pike",children:'//-----------------------------\n// Recipe: REST API client class\n//-----------------------------\n\n#pragma strict_types\n#require constant(Protocols.HTTP)\n#require constant(Standards.JSON)\n\nclass RESTClient {\n    private string base_url;\n    private string|void auth_token;\n\n    void create(string url, void|string token) {\n        base_url = url;\n        auth_token = token;\n    }\n\n    mapping get(string endpoint, void|mapping params) {\n        return request("GET", endpoint, 0, params);\n    }\n\n    mapping post(string endpoint, void|mapping data) {\n        return request("POST", endpoint, data, 0);\n    }\n\n    mapping put(string endpoint, void|mapping data) {\n        return request("PUT", endpoint, data, 0);\n    }\n\n    mapping delete(string endpoint) {\n        return request("DELETE", endpoint, 0, 0);\n    }\n\n    private mapping request(string method, string endpoint,\n                         void|mapping data, void|mapping params) {\n        mapping(string:string) headers = ([\n            "Accept": "application/json",\n            "Content-Type": "application/json"\n        ]);\n\n        if (auth_token) {\n            headers["Authorization"] = "Bearer " + auth_token;\n        }\n\n        string body = "";\n        if (data && sizeof(data)) {\n            body = Standards.JSON.encode(data);\n        }\n\n        // Build URL with params\n        string url = base_url + endpoint;\n        if (params && sizeof(params)) {\n            array(string) items = map(indices(params), lambda(string key) {\n                return key + "=" + params[key];\n            });\n            url += "?" + items * "&";\n        }\n\n        Protocols.HTTP.Query q = Protocols.HTTP.do_method(\n            method, url, ([]), headers, 0, body\n        );\n\n        if (q->status >= 200 && q->status < 300) {\n            return ([\n                "success": 1,\n                "status": q->status,\n                "data": Standards.JSON.decode(q->data() || "{}")\n            ]);\n        } else {\n            return ([\n                "success": 0,\n                "status": q->status,\n                "error": q->status_desc\n            ]);\n        }\n    }\n}\n\n// Usage\nvoid main() {\n    RESTClient api = RESTClient("https://api.example.com");\n\n    mapping result = api->get("/users/1");\n    if (result->success) {\n        mapping user = result->data;\n        write("User: %s\\n", user->name);\n    } else {\n        werror("Error: %s\\n", result->error);\n    }\n}\n'})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"rate-limiting",children:"Rate Limiting"}),"\n",(0,r.jsx)(e.h3,{id:"polite-crawler",children:"Polite Crawler"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-pike",children:'//-----------------------------\n// Recipe: Rate limiter for web requests\n//-----------------------------\n\n#pragma strict_types\n\nclass RateLimiter {\n    private float min_interval;\n    private int last_request = 0;\n\n    void create(int requests_per_second) {\n        min_interval = 1.0 / requests_per_second;\n    }\n\n    void throttle() {\n        int current = time();\n        float elapsed = current - last_request;\n\n        if (elapsed < min_interval) {\n            float sleep_time = min_interval - elapsed;\n            sleep((int)(sleep_time * 1000000) / 1000);\n        }\n\n        last_request = time();\n    }\n}\n\nvoid main() {\n    RateLimiter limiter = RateLimiter(2);  // 2 requests/sec\n\n    array(string) urls = ({\n        "https://example.com/page1",\n        "https://example.com/page2",\n        "https://example.com/page3"\n    });\n\n    foreach(urls; string url) {\n        limiter->throttle();\n\n        Protocols.HTTP.Query q = Protocols.HTTP.get_url(url);\n        if (q->status == 200) {\n            write("Fetched: %s (%d bytes)\\n", url, sizeof(q->data()));\n        }\n    }\n}\n'})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"creating-a-web-crawler",children:"Creating a Web Crawler"}),"\n",(0,r.jsx)(e.h3,{id:"basic-web-crawler",children:"Basic Web Crawler"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-pike",children:'//-----------------------------\n// Recipe: Simple web crawler\n//-----------------------------\n\n#pragma strict_types\n#require constant(Protocols.HTTP)\n\nclass WebCrawler {\n    private string start_url;\n    private int max_depth;\n    private set(string) visited = (<>);\n    private array(string) queue = ({});\n    private RateLimiter limiter;\n\n    void create(string url, void|int depth, void|int rps) {\n        start_url = url;\n        max_depth = depth || 2;\n        limiter = RateLimiter(rps || 2);\n        queue += ({url});\n    }\n\n    array(string) extract_links(string html) {\n        array(string) links = ({});\n        object re = Regexp.PCRE.Simple("<a\\\\s+href=[\'\\"]([^\'\\"]+)[\'\\"]");\n\n        int pos = 0;\n        while (pos < sizeof(html)) {\n            array(string) match = re->match(html, pos);\n            if (!match) break;\n            links += ({match[1]});\n            pos = html->search(match[0], pos) + sizeof(match[0]);\n        }\n\n        return links;\n    }\n\n    void crawl() {\n        while (sizeof(queue)) {\n            string url = queue[0];\n            queue = queue[1..];\n\n            if (visited[url]) continue;\n            visited[url] = 1;\n\n            limiter->throttle();\n\n            Protocols.HTTP.Query q = Protocols.HTTP.get_url(url);\n            if (q && q->status == 200) {\n                write("Crawled: %s (%d bytes)\\n", url, sizeof(q->data()));\n\n                array(string) links = extract_links(q->data());\n                queue += links;\n            }\n        }\n    }\n}\n\nvoid main() {\n    WebCrawler crawler = WebCrawler("https://example.com", 2, 1);\n    crawler->crawl();\n}\n'})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"see-also",children:"See Also"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.a,{href:"/docs/network/sockets",children:"Sockets"})," - Low-level socket programming"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.a,{href:"/docs/network/cgi-programming",children:"CGI Programming"})," - Server-side web scripting"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.a,{href:"/docs/network/internet-services",children:"Internet Services"})," - Email, FTP, DNS"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.a,{href:"/docs/basics/strings",children:"Strings"})," - Text processing"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.a,{href:"/docs/basics/pattern-matching",children:"Pattern Matching"})," - Advanced text parsing"]}),"\n"]})]})}function p(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(d,{...n})}):d(n)}},8453(n,e,t){t.d(e,{R:()=>a,x:()=>o});var i=t(6540);const r={},s=i.createContext(r);function a(n){const e=i.useContext(s);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:a(n.components),i.createElement(s.Provider,{value:e},n.children)}}}]);